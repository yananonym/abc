\subsection{Probability Distribution Simplex and Measure-Theoretic Foundations}

\subsubsection{From Discrete Lattice to Probability Measures}

The traditional view of integers as points on a discrete number line $\mathbb{Z}$ must be replaced with a measure-theoretic perspective when using the normalization framework. Each integer $n$ induces a probability measure $\mu_n$ on the prime field:

\begin{equation}
\mu_n = \sum_{k=1}^{\infty} w_k(n) \delta_{p_k}
\end{equation}

where $\delta_{p_k}$ is the Dirac point mass at prime $p_k$. This measure assigns weight $w_k(n)$ to each prime, exactly the normalized exponent.

The space of all such measures is:

\begin{equation}
\mathcal{M}(\mathbb{P}) = \left\{ \mu = \sum_k w_k \delta_{p_k} : w_k \geq 0, \; \sum_k w_k = 1 \right\} \cong \Delta^{\infty}
\end{equation}

Thus, each integer defines a \emph{unique probability measure} on the primes.

\subsubsection{Weak Convergence and Polish Space Structure}

Equip $\mathcal{M}(\mathbb{P})$ with the \emph{weak topology}: a sequence of measures $\mu_n$ converges weakly to $\mu$ if:

\begin{equation}
\int f \, d\mu_n \to \int f \, d\mu \quad \text{for all continuous bounded functions } f
\end{equation}

With this topology, $\mathcal{M}(\mathbb{P})$ becomes a \emph{Polish space}, a complete separable metric space. This enables the use of deep results from descriptive set theory.

The metric is the Prokhorov metric:

\begin{equation}
d_{\text{Prok}}(\mu, \mu') = \inf\{\epsilon > 0 : \mu(A) \leq \mu'(A^{\epsilon}) + \epsilon \text{ for all closed } A\}
\end{equation}

where $A^{\epsilon} = \{x : d(x, A) < \epsilon\}$ is the $\epsilon$-fattening of $A$.

\subsubsection{Tightness and Prokhorov's Theorem}

A family of probability measures is \emph{tight} if for every $\epsilon > 0$, there exists a compact set $K$ such that $\mu(K) > 1 - \epsilon$ for all measures in the family.

By Prokhorov's theorem, a tight family of measures on a Polish space is relatively compact, meaning any sequence has a convergent subsequence.

For the integers, the question becomes: \emph{Is the set of normalized exponent measures $\{\mu_n : n \in \mathbb{N}\}$ tight?}

The answer is \emph{no} in the usual sense, because as $n$ grows, its prime factors spread across an increasingly large range. However, the set is \emph{asymptotically tight}: the measures concentrate near a limiting ``average'' prime distribution given by the prime number theorem.

\subsubsection{Probability Measures Induced by the Prime Number Theorem}

The \emph{prime number theorem} states:

\begin{equation}
\pi(x) \sim \frac{x}{\log x}
\end{equation}

This induces a natural probability measure on the primes, weighted by their density:

\begin{equation}
\mu_{\text{PNT}} = \int_0^{\infty} \delta_{\log p(x)} \, d\left(\frac{dx}{x \log x}\right)
\end{equation}

In other words, primes are distributed logarithmically, with density $\sim 1/\log x$ at position $x$.

For a random integer $n$ with uniform distribution on $\{1, \ldots, N\}$, the empirical normalized weight measure converges weakly (as $N \to \infty$) to a measure supported on the logarithmically-weighted prime distribution.

\subsubsection{Coupling and Comparison of Measures}

Given two integers $n$ and $m$ with induced measures $\mu_n$ and $\mu_m$, a \emph{coupling} is a joint probability measure $\gamma$ on $\mathbb{P} \times \mathbb{P}$ with marginals $\mu_n$ and $\mu_m$.

The set of couplings for $(\mu_n, \mu_m)$ is:

\begin{equation}
\Gamma(\mu_n, \mu_m) = \left\{ \gamma : \gamma(\cdot \times \mathbb{P}) = \mu_n, \; \gamma(\mathbb{P} \times \cdot) = \mu_m \right\}
\end{equation}

Different couplings represent different ways of ``pairing up'' the prime factors of $n$ and $m$. The optimal coupling (in the sense of minimizing total cost) reveals the most efficient way to transform $n$ into $m$ using prime operations.

\subsubsection{Disintegration and Conditional Measures}

The disintegration theorem allows decomposition of a measure on a product space according to a marginal. For a measure $\mu$ on $\mathbb{P} \times \mathbb{N}$ (pairing primes with integers), disintegrate as:

\begin{equation}
\mu = \int_{\mathbb{N}} \mu_n \, d\lambda(n)
\end{equation}

where $\lambda$ is the marginal on $\mathbb{N}$ and $\mu_n$ are conditional measures given $n$.

This decomposition is useful for analyzing how the prime distribution varies conditioned on properties of $n$ (e.g., $n$ even, $n$ prime, etc.).

\subsubsection{Absolutely Continuous and Singular Measures}

Two probability measures $\mu$ and $\nu$ are \emph{mutually absolutely continuous} ($\mu \sim \nu$) if they have the same null sets:

\begin{equation}
\mu(A) = 0 \iff \nu(A) = 0
\end{equation}

They are \emph{mutually singular} ($\mu \perp \nu$) if there exists a set $A$ with $\mu(A) = 1$ and $\nu(A) = 0$.

For two integers $n$ and $m$, the question of whether $\mu_n \sim \mu_m$ determines whether they share the same \emph{essential prime support}. If disjoint in prime factors, $\mu_n \perp \mu_m$.

The Lebesgue decomposition theorem ensures that every pair of measures can be written as:

\begin{equation}
\mu = a \cdot \mu_{\text{ac}} + \mu_{\text{sing}}
\end{equation}

where $\mu_{\text{ac}}$ is absolutely continuous relative to $\nu$ and $\mu_{\text{sing}} \perp \nu$.

\subsubsection{Radon-Nikodym Derivative and Likelihood Ratios}

If $\mu \ll \nu$ (μ is absolutely continuous with respect to ν), the Radon-Nikodym derivative is:

\begin{equation}
\frac{d\mu}{d\nu} = f
\end{equation}

For normalized weight measures, this gives a likelihood ratio:

\begin{equation}
f_{\mu_n / \mu_m} = \frac{w_k(n)}{w_k(m)} \quad \text{(for masses at } p_k \text{)}
\end{equation}

The integral:

\begin{equation}
D_{\text{KL}}(\mu_n || \mu_m) = \int \log f_{\mu_n / \mu_m} \, d\mu_n = \sum_k w_k(n) \log \frac{w_k(n)}{w_k(m)}
\end{equation}

is the Kullback-Leibler divergence, quantifying how different the prime distributions of $n$ and $m$ are.

\subsubsection{Signed and Complex Measures}

Extend the framework to \emph{signed measures} (allowing negative masses) and \emph{complex measures} (allowing complex values). This is natural when dealing with shifted systems where exponents can be negative:

\begin{equation}
\mu_n = \sum_k b_k^{(q)} \delta_{p_k + q}
\end{equation}

The $b_k^{(q)}$ can be negative, making $\mu_n$ a signed measure with positive and negative parts.

The Jordan decomposition separates:

\begin{equation}
\mu_n = \mu_n^+ - \mu_n^-, \quad \mu_n^+, \mu_n^- \geq 0
\end{equation}

The total variation norm is:

\begin{equation}
||\mu_n||_{\text{TV}} = |\mu_n^+|(\mathbb{P}) + |\mu_n^-|(\mathbb{P})
\end{equation}

For shifted systems, $||\mu_n||_{\text{TV}} = \sum_k |b_k^{(q)}| = \Omega_E(n)$, which is precisely the Omega function in the shifted system.

\subsubsection{Weak* Topology and Dual Space}

The space of finite signed measures is the dual of the space of continuous bounded functions:

\begin{equation}
\mathcal{M}(\mathbb{P})^* = C_0(\mathbb{P})
\end{equation}

The weak* topology on $\mathcal{M}(\mathbb{P})$ makes it compact. By the Banach-Alaoglu theorem, any bounded sequence of measures has a weakly convergent subsequence.

This compactness is essential: it guarantees that limiting operations (like taking averages over infinitely many integers) always produce well-defined measures.

\subsubsection{Hausdorff Dimension and Fractal Structure}

For a subset $S \subset \mathbb{N}$ (e.g., primes, smooth numbers, etc.), analyze its image in the measure space:

\begin{equation}
\mathcal{I}(S) = \{\mu_n : n \in S\} \subset \mathcal{M}(\mathbb{P})
\end{equation}

The Hausdorff dimension of $\mathcal{I}(S)$ in the Prokhorov metric measures the \emph{dimensional complexity} of $S$ in the prime structure. For example:

\begin{itemize}
\item Primes: dimension $0$ (isolated points)
\item Prime powers: dimension $0$ (dimension is the measure support)
\item Smooth numbers: dimension $> 0$ (concentrated support)
\item All integers: dimension $\infty$ (dense in $\mathcal{M}(\mathbb{P})$)
\end{itemize}

\subsubsection{Invariant and Ergodic Measures}

A probability measure $\mu$ on $\mathcal{M}(\mathbb{P})$ is \emph{invariant} under a transformation $T$ if:

\begin{equation}
T_* \mu = \mu
\end{equation}

For the transformation $T(n) = n \cdot p$ (multiplication by prime $p$), an invariant measure would give a weighted distribution that is unchanged by adding factors of $p$.

By the Birkhoff ergodic theorem, the time average of any observable converges to its space average for ergodic measures:

\begin{equation}
\lim_{N \to \infty} \frac{1}{N} \sum_{n \leq N} f(\mu_n) = \int f \, d\mu_{\infty}
\end{equation}

where $\mu_{\infty}$ is the ergodic limit measure. This provides a bridge between individual factorizations and collective statistical behavior.
